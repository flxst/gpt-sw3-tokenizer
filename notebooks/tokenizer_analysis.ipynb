{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5d025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from typing import List\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from test_data import TEST_EXAMPLES\n",
    "\n",
    "\n",
    "from ipywidgets import interact, Checkbox\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from plots import plot_histogram, compare_vocab, plot_overview, plot_timelines, plot_overview_data, plot_vocab_size\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf14dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models() -> List[str]:\n",
    "    return sorted(os.listdir(OUTPUT_DIR))\n",
    "    \n",
    "models = get_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c7ac4",
   "metadata": {},
   "source": [
    "# 1. Show examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e08681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\N{ANGSTROM SIGN}\", \"\\N{LATIN CAPITAL LETTER A WITH RING ABOVE}\", \"\\u0041\\u030A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725861c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = TEST_EXAMPLES + [\n",
    "    'Allmänna Allmänna',\n",
    "    \"<|endoftext|> test\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22276197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example_model(example, model, show_tokenization):\n",
    "    _id = model.split(\"_\")[0]\n",
    "    tokenizer_file = join(OUTPUT_DIR, model, \"tokenizer.json\")\n",
    "    tokenizer = Tokenizer.from_file(tokenizer_file)\n",
    "    tokenizer_fast = PreTrainedTokenizerFast(tokenizer_file=tokenizer_file)\n",
    "    encoding = tokenizer_fast.encode(example)\n",
    "    print(f\"============ {model}\")\n",
    "    print(f\"example: '{example}'\")\n",
    "    print(f\"pre-tok: {tokenizer.pre_tokenizer.pre_tokenize_str(example)}\")\n",
    "    # print(encoding)\n",
    "    example_encoded = tokenizer_fast.convert_ids_to_tokens(encoding)\n",
    "    print(f\"encoded: {example_encoded} --- {len(example_encoded)}\")\n",
    "    example_decoded = tokenizer_fast.decode(encoding)\n",
    "    print(f\"decoded: '{example_decoded}'\")\n",
    "    example_decoded_bytes = example_decoded.encode(\"utf-8\")\n",
    "    print(f\"decoded as bytes: {example_decoded_bytes}\")\n",
    "    print()\n",
    "    example_decoded_per_token = [tokenizer_fast.decode(elem).replace(\"\\n\", \"↩\\n\").replace(\" \", \"-\") for elem in encoding]\n",
    "    \n",
    "    if show_tokenization:\n",
    "        COLORS = [\"red\", \"blue\"] # \"green\"] # , \"blue\", \"magenta\", \"cyan\"]\n",
    "        for i, elem in enumerate(example_decoded_per_token):\n",
    "            print(colored(elem, COLORS[i%len(COLORS)]), end=\"\")\n",
    "        print()\n",
    "        print(f\"> {len(example_decoded_per_token)} tokens\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_examples(example=test_examples, model=[\"ALL\"] + models, show_tokenization=False):\n",
    "    if model == \"ALL\":\n",
    "        for model in sorted(models):\n",
    "            show_example_model(example, model, show_tokenization)\n",
    "    else:\n",
    "        show_example_model(example, model, show_tokenization)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\"ℌej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # ℌ, H --- ÅNGSTRÖM, Å, A+°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9dc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFC\n",
    "\"ℌej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # ℌ, H --- Å, Å, Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc579495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFKD\n",
    "\"Hej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # H, H --- A+°, A+°, A+°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFKC\n",
    "\"Hej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # H, H --- Å, Å, Å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f1124",
   "metadata": {},
   "source": [
    "# 2. Subwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ca3c5",
   "metadata": {},
   "source": [
    "### 2a. Subword Length Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f1d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_histogram(model_1=models, model_2=[None] + models, xlim=20, ylim=15000):\n",
    "    plot_histogram(model_1, model_2, xlim, ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5a7f5",
   "metadata": {},
   "source": [
    "### 2b. Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9236d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_compare_vocab(model_1=models, model_2=models, nr=5):\n",
    "    v, ex1, ex2 = compare_vocab(model_1, model_2)\n",
    "    print(v)\n",
    "    print()\n",
    "    print(\"=== only model 1 ===\")\n",
    "    print(ex1[:nr])\n",
    "    print()\n",
    "    print(\"=== only model 2 ===\")\n",
    "    print(ex2[:nr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeee434",
   "metadata": {},
   "source": [
    "### 2c. Vocabulary Size & Subword Length Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b95a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_vocab_size(model=models):\n",
    "    plot_vocab_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42dc678",
   "metadata": {},
   "source": [
    "# 3. Multilinguality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca36736",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_multilinguality = [model for model in models if model.count(\"_3\") > 0]\n",
    "models_multilinguality = [model for model in models_multilinguality if not \"all\" in model]\n",
    "models_multilinguality.sort(key = lambda x: x.split(\"_3\")[-1])\n",
    "models_multilinguality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8899081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview_corpus(models_multilinguality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f00827",
   "metadata": {},
   "source": [
    "### 3a. Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overview_data(models_multilinguality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a74a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overview(models_multilinguality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912f796",
   "metadata": {},
   "source": [
    "### 3b. Intersection Matrix (Subword Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6047519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection_matrix(subword_length_threshold = None, normalize = True, plot = True):\n",
    "\n",
    "    lang = [model.split(\"_3\")[-1] for model in models_multilinguality]\n",
    "    N = len(lang)\n",
    "    intersection_matrix = np.zeros([N, N])\n",
    "\n",
    "    for i, j in product(range(N), range(N)):\n",
    "        model_1 = models_multilinguality[i]\n",
    "        model_2 = models_multilinguality[j]\n",
    "        lang_1 = model_1.split(\"_3\")[-1]\n",
    "        lang_2 = model_2.split(\"_3\")[-1]\n",
    "        v, _, _ = compare_vocab(model_1, model_2, subword_length_threshold)\n",
    "        # print(lang_1, lang_2, v[\"intersection\"])\n",
    "        intersection_matrix[i, j] = v[\"intersection\"]\n",
    "    \n",
    "    # print(lang)\n",
    "    # print(intersection_matrix)\n",
    "    if normalize:\n",
    "        for i, j in product(range(N), range(N)):\n",
    "            if i != j:\n",
    "                intersection_matrix[i, j] = intersection_matrix[i, j] / intersection_matrix[i, i]\n",
    "        for i in range(N):\n",
    "            intersection_matrix[i, i] = 1.0\n",
    "    # print(intersection_matrix)\n",
    "    \n",
    "    if plot:\n",
    "        ax = sns.heatmap(intersection_matrix, \n",
    "                         xticklabels=lang,\n",
    "                         yticklabels=lang,\n",
    "                         cmap=\"binary\",\n",
    "                         vmin=0,\n",
    "                         annot=True,\n",
    "        )\n",
    "    else:\n",
    "        return intersection_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8594ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1819f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c68c34c",
   "metadata": {},
   "source": [
    "### 3c. Intersection Timeline (Subword Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b710fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 2 # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b978f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = [model.split(\"_3\")[-1] for model in models_multilinguality]\n",
    "lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3686dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatrices = {i: get_intersection_matrix(i, normalize=True, plot=False) for i in range(1, MAX+1)}\n",
    "# imatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139be25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_all = p(x|all) = 1st column\n",
    "p_all = {i: imatrices[i][0] if len(imatrices[i]) > 0 else None for i in range(1, MAX+1)} \n",
    "# p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa801e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timelines_all = {\n",
    "    lang[l]: [p_all[i][l] for i in range(1, MAX+1)]\n",
    "    for l in range(len(lang))   \n",
    "}\n",
    "# timelines_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_x = p(all|x) = 1st row\n",
    "p_x = {i: imatrices[i][:,0] if len(imatrices[i]) > 0 else None for i in range(1, MAX+1)}\n",
    "# p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733adf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "timelines_x = {\n",
    "    lang[l]: [p_x[i][l] for i in range(1, MAX+1)]\n",
    "    for l in range(len(lang))   \n",
    "}\n",
    "# timelines_x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253754d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_timelines(\n",
    "    [timelines_all, timelines_x], \n",
    "    lang, \n",
    "    ylabel=[\"p(x|all)\", \"p(all|x)\"], \n",
    "    title=[\n",
    "        \"Of the subwords in the ALL vocab, how many are in the X vocab?\", \n",
    "        \"Of the subwords in the X vocab, how many are in the ALL vocab?\"\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gpt-sw3-tokenizer",
   "language": "python",
   "name": "venv-gpt-sw3-tokenizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
