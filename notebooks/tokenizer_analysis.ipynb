{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13956492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, isfile\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from src.hardcoded.test_data import TEST_EXAMPLES\n",
    "from src.env import Env\n",
    "\n",
    "\n",
    "from ipywidgets import interact, Checkbox\n",
    "\n",
    "from plots import get_models_in_output_dir\n",
    "from plots import tokenize_hf\n",
    "from plots import tokenize_sp\n",
    "from plots import display\n",
    "from plots import decode_hack\n",
    "\n",
    "from plots import get_models_multilinguality\n",
    "from plots import get_intersection\n",
    "from plots import get_intersections\n",
    "\n",
    "from plots import plot_histogram, compare_vocab, plot_overview, plot_timelines, plot_overview_data, plot_vocab_size\n",
    "\n",
    "from plots import get_list_of_results\n",
    "from plots import read_results\n",
    "from plots import retrieve_groups_from_results\n",
    "from plots import retrieve_parameters_from_results\n",
    "from plots import color as plots_color\n",
    "from plots import extract\n",
    "\n",
    "from analysis import analyze_vocab\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "\n",
    "LANGUAGES_GPTSW3 = [\"sv\", \"en\", \"no\", \"da\", \"is\", \"cd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6649e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(\"..\")\n",
    "for k, v in env.__dict__.items():\n",
    "    print(f\"{k.ljust(13)}: {v}\")\n",
    "OUTPUT_DIR = env.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cbdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa9a200",
   "metadata": {},
   "source": [
    "# 0. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ba6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models_in_output_dir()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeac9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf26a1d",
   "metadata": {},
   "source": [
    "# 1. Tokenization examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6032cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example_model(example: str, \n",
    "                       model: str, \n",
    "                       show_tokenization: bool = True, \n",
    "                       verbose: bool = False):\n",
    "    \n",
    "    _id = model.split(\"_\")[0]\n",
    "    \n",
    "    if isfile(join(OUTPUT_DIR, model, \"tokenizer.json\")):\n",
    "        texample = tokenize_hf(model, example)\n",
    "    elif isfile(join(OUTPUT_DIR, model, \"model.model\")):\n",
    "        texample = tokenize_sp(model, example)\n",
    "    else:\n",
    "        raise Exception(f\"ERROR! could not find tokenizer for model = {model}.\")\n",
    "    # assert \"\".join(texample['de-tokenized_elementwise']) == texample['de-tokenized'], f\"ERROR de-tokenized elementwise!\"\n",
    "    \n",
    "    print(f\"\\n============ {model}\")\n",
    "    print(\"\\noriginal:\")\n",
    "    print(example)\n",
    "    # print(f\"example: '{example}'\")\n",
    "    # print(f\"\\nencoded: {texample['encoded']}\")\n",
    "    # print(f\"\\ntokenized: {texample['tokenized']} --- {len(texample['tokenized'])}\")\n",
    "    # print(f\"\\nde-tokenized: '{texample['de-tokenized']}'\")\n",
    "    # print(f\"\\nde-tokenized elementwise: {texample['de-tokenized_elementwise']}\")\n",
    "    \n",
    "    if show_tokenization: \n",
    "        print(\"\\ntokenized:\")\n",
    "        display(texample['tokenized'], verbose=verbose)\n",
    "        print(\"de-tokenized:\")\n",
    "        display(texample['de-tokenized_elementwise'], \n",
    "                show_linebreak=True, \n",
    "                equal_to_original=example == texample['de-tokenized'],\n",
    "                verbose=verbose)\n",
    "        if 'de-tokenized_elementwise_hack' in texample.keys():\n",
    "            print(\"\\ndecoded + hack:\")\n",
    "            display(texample['de-tokenized_elementwise_hack'], show_linebreak=True, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23037e12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_examples(example=TEST_EXAMPLES, \n",
    "                  model=models, \n",
    "                  show_tokenization=True, \n",
    "                  verbose=False):\n",
    "    show_example_model(example, model, show_tokenization, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb46de",
   "metadata": {},
   "source": [
    "# 2. Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd225238",
   "metadata": {},
   "source": [
    "### 2a. Subword Length Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb788658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_histogram(model_1=models, model_2=[None] + models, xlim=20, ylim=15000):\n",
    "    plot_histogram(model_1, model_2, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9eb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e9fda",
   "metadata": {},
   "source": [
    "### 2b. Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8d43f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_compare_vocab(model_1=models, model_2=models, nr=30):\n",
    "    v, ex1, ex2 = compare_vocab(model_1, model_2, 1000000, 1000000)\n",
    "    print(v)\n",
    "    print()\n",
    "    print(\"=== only model 1 ===\")\n",
    "    print(ex1[:nr])\n",
    "    print()\n",
    "    print(\"=== only model 2 ===\")\n",
    "    print(ex2[:nr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f2edd",
   "metadata": {},
   "source": [
    "### 2d. Analyze vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40411510",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_analyze_vocab(model=models):\n",
    "    analyze_vocab(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec907493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c12ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_1a(_unk_rate, _ctcl, _languages, _ymin, _ymax):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # colors = {\"da\": \"r\", \"en\": \"g\", \"is\": \"b\", \"no\": \"purple\", \"sv\": \"orange\"}\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for l, language in enumerate(_languages):\n",
    "        try:\n",
    "            ax[0].bar(language, _unk_rate[language], color=plots_color(language))\n",
    "            ax[1].bar(language, _ctcl[language], color=plots_color(language))\n",
    "        except KeyError:\n",
    "            ax[0].bar(language, 0, color=plots_color(language))\n",
    "            ax[1].bar(language, 0, color=plots_color(language))\n",
    "    for i in range(2):\n",
    "        ax[i].set_ylim([_ymin, _ymax])\n",
    "    ax[0].set_title(\"unknown rate (lower = better)\")\n",
    "    ax[1].set_title(\"closeness to character level (lower = better)\")\n",
    "    \n",
    "def plot_evaluation_1b(_f, _p, _add_f, _add_p, _languages, _ymax, languages_gptsw3):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if languages_gptsw3:\n",
    "        _languages = LANGUAGES_GPTSW3\n",
    "    \n",
    "    add = len(_add_f) and len(_add_p)\n",
    "    # colors = {\"da\": \"r\", \"en\": \"g\", \"is\": \"b\", \"no\": \"purple\", \"sv\": \"orange\"}\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for l, language in enumerate(_languages):\n",
    "        try:\n",
    "            ax[0].bar(language, _f[language], edgecolor=plots_color(language), color=\"w\")\n",
    "            ax[1].bar(language, _p[language], edgecolor=plots_color(language), color=\"w\")\n",
    "        except KeyError:\n",
    "            ax[0].bar(language, 0, color=plots_color(language))\n",
    "            ax[1].bar(language, 0, color=plots_color(language))\n",
    "            \n",
    "    if add:\n",
    "        for l_tokenizer, language_tokenizer in enumerate(_languages):\n",
    "            for l, language in enumerate(_languages):\n",
    "                ax[0].scatter(language, _add_f[language_tokenizer][language][0], color=plots_color(language_tokenizer), label=language if language == language_tokenizer else None)\n",
    "                ax[1].scatter(language, _add_p[language_tokenizer][language][0], color=plots_color(language_tokenizer), label=language if language == language_tokenizer else None)\n",
    "                \n",
    "    ax[0].set_ylim([1, _ymax])\n",
    "    ax[1].set_ylim([0, 1])\n",
    "    if add:\n",
    "        ax[1].legend()\n",
    "        \n",
    "    ax[0].set_title(\"fertility\")\n",
    "    ax[1].set_title(\"proportion of continued words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a03c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_evaluation_1(result=get_list_of_results(), vocab_size=[64000], add=False, languages_gptsw3=False):\n",
    "    r = read_results(result)\n",
    "    \n",
    "    # filter vocab_size\n",
    "    r = {k: v for k, v in r.items() if k.endswith(f\"v{vocab_size}_{result}\")}\n",
    "    \n",
    "    if add:\n",
    "        add_results  = [elem for elem in get_list_of_results() if elem != result]\n",
    "        add_r = {add_result: read_results(add_result) for add_result in add_results}\n",
    "\n",
    "    if len(r) != 1:\n",
    "        print(f\"> can't show evaluation as len(results) = {len(r)} is != 1\")\n",
    "    \n",
    "    groups = retrieve_groups_from_results(r)\n",
    "    \n",
    "    @interact\n",
    "    def show_evaluation_1_detail(group=groups, ymin=0.0, ymax=4.0):\n",
    "        vocabs, vocabs_models, files, languages, languages_files = retrieve_parameters_from_results(group, r, verbose=False)\n",
    "        results_filtered = r\n",
    "        unk_rate, ctcl, fertility, proportion = extract(results_filtered, vocabs_models, vocabs, languages_files, languages)\n",
    "         \n",
    "        if 0:\n",
    "            print(\"languages:\", languages)\n",
    "            print(\"unk_rate:\", unk_rate)\n",
    "            print(\"ctcl:\", ctcl)\n",
    "            print(\"fertility:\", fertility)\n",
    "            print(\"proportion:\", proportion)\n",
    "        \n",
    "        add_fertility, add_proportion = {}, {}\n",
    "        if add:\n",
    "            for k in add_r.keys():\n",
    "                add_vocabs, add_vocabs_models, add_files, add_languages, add_languages_files = retrieve_parameters_from_results(group, add_r[k], verbose=False)\n",
    "                add_results_filtered = add_r[k]            \n",
    "                _, _, add_fertility[k], add_proportion[k] = extract(add_results_filtered, add_vocabs_models, add_vocabs, add_languages_files, add_languages)\n",
    "                \n",
    "            if OUTPUT_DIR.endswith(\"output_arxiv_1\"):\n",
    "                # hack: replace 4da by da, 4no by no, ..\n",
    "                add_fertility = {k[1:]: v for k, v in add_fertility.items()}\n",
    "                add_proportion = {k[1:]: v for k, v in add_proportion.items()}\n",
    "            else:\n",
    "                # hack: replace tokenizer1_da by da, tokenizer1_no by no\n",
    "                add_fertility = {k.split(\"_\")[-1]: v for k, v in add_fertility.items()}\n",
    "                add_proportion = {k.split(\"_\")[-1]: v for k, v in add_proportion.items()}\n",
    "            \n",
    "            # print(\"add_fertility:\", add_fertility)\n",
    "            # print(\"add_proportion:\", add_proportion)\n",
    "\n",
    "        # plot_evaluation_1a(unk_rate, ctcl, languages, ymin, ymax)\n",
    "        plot_evaluation_1b(fertility, proportion, add_fertility, add_proportion, languages, ymax, languages_gptsw3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de7d94",
   "metadata": {},
   "source": [
    "# 3. Vocab Size & Multilinguality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650077e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = get_models_multilinguality(models, verbose=False)\n",
    "ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview_corpus(models_multilinguality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a61f2",
   "metadata": {},
   "source": [
    "### 3a. Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ml):\n",
    "    plot_overview_data(ml[\"models_pure\"].values(), verbose=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3d9e0a8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "if len(ml):\n",
    "    plot_overview(ml[\"models_pure\"].values(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e640fa23",
   "metadata": {},
   "source": [
    "### 3b. Evaluation #1: Vocabulary Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39deb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = [10000, 20000, 30000, 40000, 51200, 64000]  # , 80000, 96000, 112000, 128000]\n",
    "vocabs_1 = vocabs\n",
    "vocabs_2 = vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ml):\n",
    "    timelines = get_intersections(ml, vocabs_1, vocabs_2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfa126aa",
   "metadata": {},
   "source": [
    "### ml['lang_all'] contains multilingual tokenizer in ./output/multilinguality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_1_fixed(_overlap_abs, _overlap_rel, _ymax):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # colors = {\"da\": \"r\", \"en\": \"g\", \"is\": \"b\", \"no\": \"purple\", \"sv\": \"orange\"}\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    ax = [ax,]\n",
    "    for l, language in enumerate(LANGUAGES_GPTSW3):\n",
    "        try:\n",
    "            ax[0].bar(language, _overlap_abs[language], color=plots_color(language), label=language)\n",
    "        except KeyError:\n",
    "            ax[0].bar(language, 0, color=plots_color(language))\n",
    "    ax[0].set_ylim([0, _ymax])\n",
    "    # ax[0].legend()\n",
    "        \n",
    "    ax[0].set_title(\"vocabulary overlap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60922ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_evaluation_1_fixed(tokenizer=ml['lang_all'], vocab_size=vocabs_2, absolute=[False, True]):\n",
    "    if tokenizer is not None:\n",
    "        lang_1 = tokenizer\n",
    "        vocab_2 = vocab_size\n",
    "        t_abs = timelines['abs'][lang_1][vocab_2]\n",
    "        t_rel = timelines['rel'][lang_1][vocab_2]\n",
    "        \n",
    "        t_abs_last = {k: v[-1] for k, v in t_abs.items()}\n",
    "        t_rel_last = {k: v[-1] for k, v in t_rel.items()}\n",
    "\n",
    "        print(t_abs_last)\n",
    "        print(t_rel_last)\n",
    "        plot_evaluation_1_fixed(t_abs_last, t_rel_last, vocab_2)\n",
    "    else:\n",
    "        print(\"> lang_all is []\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48857d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_evaluation_1_varied(tokenizer=ml['lang_all'], vocab_size=vocabs_2, absolute=[True, False], languages_gptsw3=False):\n",
    "    if tokenizer is not None:\n",
    "        if languages_gptsw3:\n",
    "            _languages = LANGUAGES_GPTSW3\n",
    "        else:\n",
    "            _languages = ml['lang_pure']\n",
    "        \n",
    "        lang_1 = tokenizer\n",
    "        vocab_2 = vocab_size\n",
    "        t_abs = timelines['abs'][lang_1][vocab_2]\n",
    "        t_rel = timelines['rel'][lang_1][vocab_2]\n",
    "        \n",
    "        t_abs = {language: t_abs[language] for language in _languages}  # order languages\n",
    "        t_rel = {language: t_rel[language] for language in _languages}  # order languages\n",
    "\n",
    "        if absolute:\n",
    "            plot_timelines(\n",
    "                vocabs_1,\n",
    "                vocab_2,\n",
    "                [t_rel, t_abs],\n",
    "                _languages, \n",
    "                ylim=[1.1, 64000],\n",
    "                ylabel=[\"\", \"\"], \n",
    "                title=[\"vocabulary overlap\"]*2,\n",
    "            )\n",
    "        else:\n",
    "            plot_timelines(\n",
    "                vocabs_1,\n",
    "                vocab_2,\n",
    "                [t_rel],\n",
    "                _languages, \n",
    "                ylim=[1.1],\n",
    "                ylabel=[\"relative\"], \n",
    "                title=[\"vocabulary overlap\"],\n",
    "            )\n",
    "    else:\n",
    "        print(\"> lang_all is []\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98a0de",
   "metadata": {},
   "source": [
    "### 3c. Evaluation #2: unk_rate & closeness_to_character_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_2a(_unk_rate, _ctcl, _vocabs, _languages, _ymax):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # colors = {\"da\": \"r\", \"en\": \"g\", \"is\": \"b\", \"no\": \"purple\", \"sv\": \"orange\"}\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for language in LANGUAGES_GPTSW3:\n",
    "        try:\n",
    "            ax[0].plot(_vocabs, _unk_rate[language], linestyle=None, marker=\"s\", color=plots_color(language), label=language)\n",
    "            ax[1].plot(_vocabs, _ctcl[language], linestyle=None, marker=\"s\", color=plots_color(language), label=language)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    for i in range(2):\n",
    "        ax[i].set_xlim([0, 150000])\n",
    "        ax[i].set_ylim([_ymin, _ymax])\n",
    "        ax[i].legend()\n",
    "    ax[0].set_title(\"unknown rate (lower = better)\")\n",
    "    ax[1].set_title(\"closeness to character level (lower = better)\")\n",
    "    \n",
    "def plot_evaluation_2b(_f, _p, _vocabs, _languages, _ymin, _ymax):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # colors = {\"da\": \"r\", \"en\": \"g\", \"is\": \"b\", \"no\": \"purple\", \"sv\": \"orange\"}\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for language in LANGUAGES_GPTSW3:\n",
    "        try:\n",
    "            ax[0].plot(_vocabs, _f[language], linestyle=None, marker=\"s\", color=plots_color(language), markerfacecolor=\"w\", label=language)\n",
    "            ax[1].plot(_vocabs, _p[language], linestyle=None, marker=\"s\", color=plots_color(language), markerfacecolor=\"w\", label=language)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    for i in range(2):\n",
    "        # ax[i].set_xlim([0, 150000])\n",
    "        ax[i].set_xlim([0, None])\n",
    "    ax[1].legend()\n",
    "        \n",
    "    ax[0].set_ylim([1, _ymax])\n",
    "    ax[1].set_ylim([0, 1])\n",
    "    \n",
    "    ax[0].set_title(\"fertility\")\n",
    "    ax[1].set_title(\"proportion of continued words\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc694944",
   "metadata": {},
   "source": [
    "### get_list_of_results() contains evaluation results in ./output/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_evaluation_2(result=get_list_of_results()):\n",
    "    results = read_results(result)\n",
    "    groups = retrieve_groups_from_results(results)\n",
    "    \n",
    "    @interact\n",
    "    def show_evaluation_2_detail(group=groups, ymin=0.0, ymax=4.0):\n",
    "        vocabs, vocabs_models, files, languages, languages_files = retrieve_parameters_from_results(group, results, verbose=False)\n",
    "        \n",
    "        unk_rate, ctcl, fertility, proportion = extract(results, vocabs_models, vocabs, languages_files, languages)\n",
    "\n",
    "        # plot_evaluation_2a(unk_rate, ctcl, vocabs, languages, ymin, ymax)\n",
    "        plot_evaluation_2b(fertility, proportion, vocabs, languages, ymin, ymax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gpt-sw3-tokenizer",
   "language": "python",
   "name": "venv-gpt-sw3-tokenizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
