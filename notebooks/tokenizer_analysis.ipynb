{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf389bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from typing import List\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from src.test_data import TEST_EXAMPLES\n",
    "\n",
    "\n",
    "from ipywidgets import interact, Checkbox\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from plots import plot_histogram, compare_vocab, plot_overview, plot_timelines, plot_overview_data, plot_vocab_size\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc31250",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e886859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models() -> List[str]:\n",
    "    return [elem for elem in sorted(os.listdir(OUTPUT_DIR)) if not elem.startswith(\".\")]\n",
    "    \n",
    "models = get_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795f511",
   "metadata": {},
   "source": [
    "# 1. Show examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cf5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\N{ANGSTROM SIGN}\", \"\\N{LATIN CAPITAL LETTER A WITH RING ABOVE}\", \"\\u0041\\u030A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b29622",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = TEST_EXAMPLES + [\n",
    "    'Allmänna Allmänna',\n",
    "    \"<|endoftext|> test\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example_model(example, model, show_tokenization):\n",
    "    _id = model.split(\"_\")[0]\n",
    "    tokenizer_file = join(OUTPUT_DIR, model, \"tokenizer.json\")\n",
    "    tokenizer = Tokenizer.from_file(tokenizer_file)\n",
    "    tokenizer_fast = PreTrainedTokenizerFast(tokenizer_file=tokenizer_file)\n",
    "    encoding = tokenizer_fast.encode(example)\n",
    "    print(f\"============ {model}\")\n",
    "    print(f\"example: '{example}'\")\n",
    "    print(f\"pre-tok: {tokenizer.pre_tokenizer.pre_tokenize_str(example)}\")\n",
    "    # print(encoding)\n",
    "    example_encoded = tokenizer_fast.convert_ids_to_tokens(encoding)\n",
    "    print(f\"encoded: {example_encoded} --- {len(example_encoded)}\")\n",
    "    example_decoded = tokenizer_fast.decode(encoding)\n",
    "    print(f\"decoded: '{example_decoded}'\")\n",
    "    example_decoded_bytes = example_decoded.encode(\"utf-8\")\n",
    "    print(f\"decoded as bytes: {example_decoded_bytes}\")\n",
    "    print()\n",
    "    example_decoded_per_token = [tokenizer_fast.decode(elem).replace(\"\\n\", \"↩\\n\").replace(\" \", \"-\") for elem in encoding]\n",
    "    \n",
    "    if show_tokenization:\n",
    "        COLORS = [\"red\", \"blue\"] # \"green\"] # , \"blue\", \"magenta\", \"cyan\"]\n",
    "        for i, elem in enumerate(example_decoded_per_token):\n",
    "            print(colored(elem, COLORS[i%len(COLORS)]), end=\"\")\n",
    "        print()\n",
    "        print(f\"> {len(example_decoded_per_token)} tokens\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_examples(example=test_examples, model=[\"ALL\"] + models, show_tokenization=False):\n",
    "    if model == \"ALL\":\n",
    "        for model in sorted(models):\n",
    "            show_example_model(example, model, show_tokenization)\n",
    "    else:\n",
    "        show_example_model(example, model, show_tokenization)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aab5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee0714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\"ℌej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # ℌ, H --- ÅNGSTRÖM, Å, A+°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e472c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFC\n",
    "\"ℌej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # ℌ, H --- Å, Å, Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4521073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFKD\n",
    "\"Hej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # H, H --- A+°, A+°, A+°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFKC\n",
    "\"Hej Hej --- TVÅ TVÅ TVÅ\".encode(\"utf-8\")  # H, H --- Å, Å, Å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7b912",
   "metadata": {},
   "source": [
    "# 2. Subwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b7a3c",
   "metadata": {},
   "source": [
    "### 2a. Subword Length Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c553040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_histogram(model_1=models, model_2=[None] + models, xlim=20, ylim=15000):\n",
    "    plot_histogram(model_1, model_2, xlim, ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f23af",
   "metadata": {},
   "source": [
    "### 2b. Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f1b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_compare_vocab(model_1=models, model_2=models, nr=5):\n",
    "    v, ex1, ex2 = compare_vocab(model_1, model_2, 1000000, 1000000)\n",
    "    print(v)\n",
    "    print()\n",
    "    print(\"=== only model 1 ===\")\n",
    "    print(ex1[:nr])\n",
    "    print()\n",
    "    print(\"=== only model 2 ===\")\n",
    "    print(ex2[:nr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b9c96",
   "metadata": {},
   "source": [
    "### 2c. Vocabulary Size & Subword Length Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_vocab_size(model=models):\n",
    "    plot_vocab_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57ec54",
   "metadata": {},
   "source": [
    "# 3. Multilinguality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b459b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_multilinguality = [model for model in models if model.count(\"_3\") > 0]\n",
    "core = list(set([\"_\".join(model.split(\"_\")[1:-1]) for model in models_multilinguality if model.endswith(\"da\")]))[0]\n",
    "print(core)\n",
    "models_multilinguality = [model for model in models_multilinguality if core in model]\n",
    "models_multilinguality.sort(key = lambda x: x.split(\"_3\")[-1])\n",
    "models_multilinguality = {model.split(\"_3\")[-1]: model for model in models_multilinguality}\n",
    "models_multilinguality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = list(models_multilinguality.keys())\n",
    "lang_all = [l for l in lang if l.startswith(\"all\")]\n",
    "lang_pure = [l for l in lang if not l.startswith(\"all\")]\n",
    "\n",
    "models = {k: models_multilinguality[k] for k in lang}\n",
    "models_all = {k: models_multilinguality[k] for k in lang_all}\n",
    "models_pure = {k: models_multilinguality[k] for k in lang_pure}\n",
    "\n",
    "lang, lang_all, lang_pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview_corpus(models_multilinguality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46513f",
   "metadata": {},
   "source": [
    "### 3a. Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3770c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overview_data(models_pure.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963b6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_overview(models_pure.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825df3f",
   "metadata": {},
   "source": [
    "### 3b. Intersection Matrix (Subword Length)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62dce596",
   "metadata": {},
   "source": [
    "def get_intersection_matrix(subword_length_threshold = None, normalize = True, plot = True):\n",
    "\n",
    "    lang = list(models_multilinguality.keys())\n",
    "    N = len(lang)\n",
    "    intersection_matrix = np.zeros([N, N])\n",
    "\n",
    "    for i, j in product(range(N), range(N)):\n",
    "        model_1 = models_multilinguality[lang[i]]\n",
    "        model_2 = models_multilinguality[lang[j]]\n",
    "\n",
    "        v, _, _ = compare_vocab(model_1, model_2, subword_length_threshold)\n",
    "        # print(lang_1, lang_2, v[\"intersection\"])\n",
    "        intersection_matrix[i, j] = v[\"intersection\"]\n",
    "    \n",
    "    # print(lang)\n",
    "    # print(intersection_matrix)\n",
    "    if normalize:\n",
    "        for i, j in product(range(N), range(N)):\n",
    "            if i != j:\n",
    "                intersection_matrix[i, j] = intersection_matrix[i, j] / intersection_matrix[i, i]\n",
    "        for i in range(N):\n",
    "            intersection_matrix[i, i] = 1.0\n",
    "    # print(intersection_matrix)\n",
    "    \n",
    "    if plot:\n",
    "        ax = sns.heatmap(intersection_matrix, \n",
    "                         xticklabels=lang,\n",
    "                         yticklabels=lang,\n",
    "                         cmap=\"binary\",\n",
    "                         vmin=0,\n",
    "                         annot=True,\n",
    "        )\n",
    "    else:\n",
    "        return intersection_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersection_matrix(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d341f5d",
   "metadata": {},
   "source": [
    "### 3c. Intersection Timeline (Subword Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection(lang_1, lang_2, vocab_1, vocab_2):\n",
    "    model_1 = models_multilinguality[lang_1]\n",
    "    model_2 = models_multilinguality[lang_2]\n",
    "    v, _, _ = compare_vocab(model_1, model_2, vocab_1, vocab_2)\n",
    "    return v[\"intersection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2627f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_intersection('all-a1.0', 'da', 10000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = [10000, 20000, 30000, 40000, 50000, 100000, 150000, 200000, 250000]\n",
    "VOCAB_1 = VOCAB\n",
    "VOCAB_2 = VOCAB\n",
    "\n",
    "# VOCAB_1 = [50000, 100000, 150000, 200000, 250000]\n",
    "# VOCAB_2 = [100, 1000, 10000, 20000, 30000, 40000, 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64acea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections = {\n",
    "    lang_1: {\n",
    "        lang_2: {\n",
    "            vocab_1: {\n",
    "                vocab_2: get_intersection(lang_1, lang_2, vocab_1, vocab_2)\n",
    "                for vocab_2 in VOCAB_2\n",
    "            }\n",
    "            for vocab_1 in VOCAB_1\n",
    "        }\n",
    "        for lang_2 in lang\n",
    "    }\n",
    "    for lang_1 in lang_all\n",
    "}\n",
    "\n",
    "# intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a378e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "timelines_abs = {\n",
    "    lang_1: {\n",
    "        vocab_2: {\n",
    "            lang_2: \n",
    "            [intersections[lang_1][lang_2][vocab_1][vocab_2] for vocab_1 in VOCAB_1]\n",
    "            for lang_2 in lang_pure\n",
    "        }\n",
    "        for vocab_2 in VOCAB_2\n",
    "    }\n",
    "    for lang_1 in lang_all\n",
    "}\n",
    "# timelines_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "timelines_rel = {\n",
    "    lang_1: {\n",
    "        vocab_2: {\n",
    "            lang_2: \n",
    "            [intersections[lang_1][lang_2][vocab_1][vocab_2]/intersections[lang_1][lang_1][vocab_2][vocab_2] for vocab_1 in VOCAB_1]\n",
    "            for lang_2 in lang_pure\n",
    "        }\n",
    "        for vocab_2 in VOCAB_2\n",
    "    }\n",
    "    for lang_1 in lang_all\n",
    "}\n",
    "# timelines_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db25a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_timelines(tokenizer=lang_all, vocab_size=VOCAB_2):\n",
    "    lang_1 = tokenizer\n",
    "    vocab_2 = vocab_size\n",
    "    t_abs = timelines_abs[lang_1][vocab_2]\n",
    "    t_rel = timelines_rel[lang_1][vocab_2]\n",
    "    \n",
    "    plot_timelines(\n",
    "        VOCAB_1,\n",
    "        vocab_2,\n",
    "        [t_abs, t_rel],\n",
    "        lang_pure, \n",
    "        ylim=[1.1*100000, 1.1],\n",
    "        ylabel=[\"absolute\", \"relative\"], \n",
    "        title=[\"Coverage of single-language tokenizer vocabulary\"]*2,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gpt-sw3-tokenizer",
   "language": "python",
   "name": "venv-gpt-sw3-tokenizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
