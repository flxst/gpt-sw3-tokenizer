# - unit: bytes = tokens x 2 !!!!
# - exact numbers taken from /data/tokenized on ICE2
# - these numbers use the 64k tokenizer after the "special token fix",
#   i.e. with pad_id = 0, unk_id = 1, bos_id = 2, eos_id = 3
#
category,sv,en,no,da,is,cd
articles,7273894226,99423760556,0,113571948,0,0
books_hq,389512508,47984991198,0,0,0,0
code,0,0,0,0,0,74339909140
conversational,32991443118,42296576824,306342534,1445435452,82738082,0
math,5032044222,5429485724,0,0,0,0
misc,9536206672,27497592562,26762891534,11522050690,5815907200,0
web_commoncrawl,91202739178,28274370638,46989169824,56769051528,5136857908,0
web_sources,3421698390,0,0,994596218,0,0
wiki,533730428,7461849244,253788166,199415224,29842276,0