{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02777d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc = {'figure.figsize':(8,8)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f8723",
   "metadata": {},
   "source": [
    "# DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eccabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = False\n",
    "\n",
    "if old:\n",
    "    path_dijbytes = \"dataset_sizes_bytes_OLD.csv\"\n",
    "    path_dijtokens = \"dataset_sizes_tokens_OLD.csv\"\n",
    "else:\n",
    "    path_dijbytes = \"dataset_sizes_bytes.csv\"\n",
    "    path_dijtokens = \"dataset_sizes_tokens.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"dijbytes\": path_dijbytes,\n",
    "    \"Wij\": \"../SAMPLING_WEIGHTS/SAMPLING_WEIGHTS_real.csv\",\n",
    "    \"dijtokens\": path_dijtokens,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28efd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {k: pd.read_csv(paths[k], index_col=0, comment='#') for k in paths.keys()}\n",
    "\n",
    "dfs[\"dijbytes\"] /= 10**9\n",
    "\n",
    "dfs[\"dijbytes*Wij\"] = pd.DataFrame(dfs[\"dijbytes\"].values*dfs[\"Wij\"].values, \n",
    "                                   columns=dfs[\"dijbytes\"].columns, \n",
    "                                   index=dfs[\"dijbytes\"].index)\n",
    "dfs[\"dijtokens*Wij\"] = pd.DataFrame(dfs[\"dijtokens\"].values*dfs[\"Wij\"].values, \n",
    "                                   columns=dfs[\"dijtokens\"].columns, \n",
    "                                   index=dfs[\"dijtokens\"].index)\n",
    "\n",
    "dfs[\"fijbytes\"] = dfs[\"dijbytes\"].div(dfs[\"dijbytes\"].to_numpy().sum()).multiply(100)\n",
    "dfs[\"Fijbytes\"] = dfs[\"dijbytes*Wij\"].div(dfs[\"dijbytes*Wij\"].to_numpy().sum()).multiply(100)\n",
    "dfs[\"fijtokens\"] = dfs[\"dijtokens\"].div(dfs[\"dijtokens\"].to_numpy().sum()).multiply(100)\n",
    "dfs[\"Fijtokens\"] = dfs[\"dijtokens*Wij\"].div(dfs[\"dijtokens*Wij\"].to_numpy().sum()).multiply(100)\n",
    "    \n",
    "for key in dfs.keys():\n",
    "    if key == \"Wij\":\n",
    "        dfs[key][\"total\"] = dfs[key].apply(lambda x: 0, axis=1)\n",
    "        dfs[key].loc[\"total\"] = dfs[key].apply(lambda x: 0, axis=0)\n",
    "    else:\n",
    "        dfs[key][\"total\"] = dfs[key].apply(lambda x: sum(x), axis=1)\n",
    "        dfs[key].loc[\"total\"] = dfs[key].apply(lambda x: sum(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc09ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_total(_df):\n",
    "    drop_total(_df)\n",
    "    _df[\"total\"] = 0\n",
    "    _df.loc[\"total\"] = 0\n",
    "\n",
    "def drop_total(_df):\n",
    "    _df.drop(\"total\", axis=0, inplace=True)\n",
    "    _df.drop(\"total\", axis=1, inplace=True)\n",
    "    \n",
    "def add_total(_df):\n",
    "    _df[\"total\"] = _df.apply(lambda x: sum(x), axis=1)\n",
    "    _df.loc[\"total\"] = _df.apply(lambda x: sum(x), axis=0)\n",
    "    \n",
    "def totex(_df, _name, header, tail=\"\\end{tabular}}\"):\n",
    "    t = \"\\\\scalebox{\\\\tabscale}{\"\n",
    "    t += header + \" \\n\"\n",
    "    t += _df.to_csv().replace(\",\", \" & \").replace(\"commoncrawl\", \"cc\").replace(\"conversational\", \"conv\").replace(\"\\n\", \" \\\\\\\\ \\n\").replace(\"_\", \"\\_\").replace(\"\\\\\\\\\", \"\\\\\\\\ \\\\hline\", 1)\n",
    "    if t.endswith(\" \\\\\\\\ \\n\"):\n",
    "        t = t[:-len(\" \\\\\\\\ \\n\")]\n",
    "        t += \" \\n\"\n",
    "    t = \"\\\\\\\\ \\\\hline\".join(t.rsplit(\"\\\\\\\\\", 1))  # replace last \"\\\\\" by \"\\\\ \\hline\"\n",
    "    t += tail\n",
    "    \n",
    "    path = f\"tables/{_name}.tex\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885c0f7",
   "metadata": {},
   "source": [
    "### Step 0: Plain dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "totex(dfs[\"dijbytes\"].applymap(lambda x: f\"{x:.1f}\"), \"dijbytes\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"dijbytes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "totex(dfs[\"fijbytes\"].applymap(lambda x: f\"{x:.2f}\"), \"fijbytes\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"fijbytes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361a37b",
   "metadata": {},
   "source": [
    "### Step 1: Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"Wij\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "totex(dfs[\"Wij\"], \"Wij\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"dijbytes*Wij\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "totex(dfs[\"Fijbytes\"].applymap(lambda x: f\"{x:.2f}\"), \"FFijbytes\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"Fijbytes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119e9e8",
   "metadata": {},
   "source": [
    "### Step 2: Tokenizer Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eab692",
   "metadata": {},
   "outputs": [],
   "source": [
    "totex(dfs[\"dijtokens\"], \"dijtokens_not_rounded\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "totex(dfs[\"dijtokens\"].applymap(lambda x: f\"{x/10**9:.2f}\"), \"dijtokens\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"dijtokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = dfs[\"dijtokens\"].max().max()\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b9393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "totex(dfs[\"fijtokens\"].applymap(lambda x: f\"{x:.2f}\"), \"fijtokens\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"fijtokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac630def",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = dfs[\"dijtokens\"].loc[\"total\"][\"total\"]\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"rij\"] = dfs[\"dijtokens\"]/dfs[\"dijbytes\"]/10**9\n",
    "dfs[\"rij\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1, m2 = min([elem for val in dfs[\"rij\"].values for elem in val]), max([elem for val in dfs[\"rij\"].values for elem in val])\n",
    "1/m1, 1/m2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e22dbc",
   "metadata": {},
   "source": [
    "### Step 3: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8eccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "totex(dfs[\"Fijtokens\"].applymap(lambda x: f\"{x:.2f}\"), \"FFijtokens\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"Fijtokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb42925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"Eij\"] = T*dfs[\"Fijtokens\"]/100/dfs[\"dijtokens\"]\n",
    "dfs[\"Eij\"] = dfs[\"Eij\"].fillna(0)\n",
    "zero_total(dfs[\"Eij\"])\n",
    "totex(dfs[\"Eij\"].applymap(lambda x: f\"{x:.2f}\"), \"Eij\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"Eij\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxE = dfs[\"Eij\"].max().max()\n",
    "maxE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd31e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"Eij_rounded\"] = dfs[\"Eij\"].applymap(lambda x: np.ceil(x))\n",
    "drop_total(dfs[\"Eij_rounded\"])\n",
    "dfs[\"Eij_rounded\"] = dfs[\"Eij_rounded\"].fillna(0)\n",
    "dfs[\"Eij_rounded\"] = dfs[\"Eij_rounded\"].astype(int)\n",
    "# totex(dfs[\"Eij_rounded\"].applymap(lambda x: f\"{x:.0f}\"), \"Eij_rounded\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"Eij_rounded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"Tijmax\"] = dfs[\"Eij_rounded\"]*dfs[\"dijtokens\"]/(dfs[\"Fijtokens\"]/100)\n",
    "dfs[\"Tijmax\"].drop(\"total\", axis=1, inplace=True)\n",
    "# dfs[\"Tijmax\"] = dfs[\"Tijmax\"].fillna(0)\n",
    "dfs[\"Tijmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98853e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_t = [value for array in dfs[\"Tijmax\"].values for value in array if value > 0]\n",
    "\n",
    "Tmax = min(_t)\n",
    "Tmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b71bc",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d512998",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = [elem for elem in dfs[\"Eij\"].index.to_list() if elem != \"total\"]\n",
    "J = [elem for elem in dfs[\"Eij\"].columns.to_list() if elem != \"total\"]\n",
    "I, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc211145",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tthr = T/maxE # 98.8*10**9\n",
    "Tthr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_overview(_dfs, _field, T_thr: bool = True):\n",
    "\n",
    "    verbose = 0\n",
    "    xlim = 500\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    if not isinstance(ax, list):\n",
    "        ax = [ax, None]\n",
    "\n",
    "    ax[0].set_xlim([0, xlim])\n",
    "    ax[0].set_ylim([0, 1])\n",
    "    ax[0].set_xlabel(\"t [10^9 tokens]\", fontsize=14)\n",
    "    _ = ax[0].plot()\n",
    "\n",
    "    y = 0\n",
    "    for i, category in enumerate(I):\n",
    "        for j, language in enumerate(J):\n",
    "            clr = \"r\" if (2*i+j)%2 == 0 else \"green\"\n",
    "            dijtokens = _dfs[\"dijtokens\"].iloc[i, j]/10**9\n",
    "            Fijtokens = _dfs[_field].iloc[i, j]/100\n",
    "            Tijmax = _dfs[\"Tijmax\"].iloc[i, j]/10**9\n",
    "\n",
    "            length = 2\n",
    "            y1 = [y]*length\n",
    "            y2 = [y + Fijtokens]*length\n",
    "\n",
    "            #########\n",
    "            if Fijtokens > 0:\n",
    "                E_1 = dijtokens / Fijtokens\n",
    "                if verbose:\n",
    "                    print(E_1)\n",
    "                    print(category, language, f\"{Fijtokens:.2f}\", clr)\n",
    "                    \n",
    "                _ = ax[0].plot([E_1, E_1], \n",
    "                               [y1[0], y2[0]], \n",
    "                               linestyle=\"-\", \n",
    "                               color=\"k\", \n",
    "                               label=\"E_ij = 1\" if i == 0 and j == 0 else None)\n",
    "            \n",
    "                x_unique = np.linspace(0, E_1, length)\n",
    "                _ = ax[0].fill_between(x_unique, y1, y2, color=\"green\", alpha=0.5)\n",
    "                \n",
    "                if E_1 < T/10**9:\n",
    "                    x_repeated = np.linspace(min(E_1, T/10**9), T/10**9, length) \n",
    "                    _ = ax[0].fill_between(x_repeated, y1, y2, color=\"orange\", alpha=0.5)\n",
    "                else:\n",
    "                    x_discarded = np.linspace(T/10**9, E_1, length)                   \n",
    "                    _ = ax[0].fill_between(x_discarded, y1, y2, color=\"red\", alpha=0.5)\n",
    "\n",
    "            \n",
    "            #########\n",
    "            if Fijtokens > 0.05:\n",
    "                _ = ax[0].text(10, y + 0.02, f\"{category}, {language}\")\n",
    "                _ = ax[0].text(T/10**9 + 10, y + 0.02, f\"{T/E_1/10**9:.2f}\")\n",
    "\n",
    "            y += Fijtokens\n",
    "\n",
    "    ax[0].plot([T/10**9, T/10**9], [0, 1], linestyle=\"--\", color=\"k\", label=\"T\")\n",
    "    if T_thr:\n",
    "        ax[0].plot([Tthr/10**9, Tthr/10**9], [0, 1], linestyle=\":\", color=\"k\", label=\"T_thr\")\n",
    "    _ = ax[0].legend(loc=\"upper right\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd792705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_data_overview(dfs, \"fijtokens\", T_thr=False)\n",
    "plt.savefig(\"./figs/data_overview_0.png\", facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_data_overview(dfs, \"Fijtokens\")\n",
    "plt.savefig(\"./figs/data_overview.png\", facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb5361",
   "metadata": {},
   "source": [
    "### Dataset Details"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30ac550a",
   "metadata": {},
   "source": [
    "dfs[\"Eij\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fac13c38",
   "metadata": {},
   "source": [
    "dfs[\"dijtokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "used = dfs[\"Eij\"]*dfs[\"dijtokens\"]\n",
    "# used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed92abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = dfs[\"dijtokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b615bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_repeated_discarded(_used, _existing):\n",
    "    _unique_lists = [[min(c,d) for c, d in zip(a, b)] for a, b in zip(_used.values, _existing.values)]\n",
    "    _repeated_lists = [[max(0,c-d) for c, d in zip(a, b)] for a, b in zip(_used.values, _existing.values)]\n",
    "    _discarded_lists = [[max(0,d-c) for c, d in zip(a, b)] for a, b in zip(_used.values, _existing.values)]\n",
    "    return _unique_lists, _repeated_lists, _discarded_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_lists, repeated_lists, discarded_lists = get_unique_repeated_discarded(used, existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb51453",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = pd.DataFrame(unique_lists, \n",
    "                      columns=used.columns, \n",
    "                      index=used.index)\n",
    "drop_total(unique)\n",
    "# unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated = pd.DataFrame(repeated_lists, \n",
    "                        columns=used.columns, \n",
    "                        index=used.index)\n",
    "drop_total(repeated)\n",
    "# repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0140d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded = pd.DataFrame(discarded_lists, \n",
    "                         columns=used.columns, \n",
    "                         index=used.index)\n",
    "drop_total(discarded)\n",
    "# discarded"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e04e6f6",
   "metadata": {},
   "source": [
    "s = unique + repeated + discarded\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 10))\n",
    "if not isinstance(ax, list):\n",
    "    ax = [ax, None]\n",
    "    \n",
    "width = 0.1\n",
    "\n",
    "for i, category in enumerate(I):\n",
    "    for j, language in enumerate(J):\n",
    "        u = unique.iloc[i, j]/10**9\n",
    "        r = repeated.iloc[i, j]/10**9\n",
    "        d = discarded.iloc[i, j]/10**9\n",
    "        ax[0].barh(f\"{category}, {language}\", u, width, color=\"green\", label='unique' if i == 0 and j == 0 else None)\n",
    "        ax[0].barh(f\"{category}, {language}\", r, width, left=u, color=\"orange\", label='repeated' if i == 0 and j == 0 else None)\n",
    "        ax[0].barh(f\"{category}, {language}\", d, width, left=u+r, color=\"red\", label='discarded' if i == 0 and j == 0 else None)\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].set_xlabel(\"tokens [10^9]\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figs/data_overview_2.png\", facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35257e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens_unique = unique.sum().sum()\n",
    "tokens_repeated = repeated.sum().sum()\n",
    "tokens_discarded = discarded.sum().sum()\n",
    "tokens_all = tokens_unique + tokens_repeated\n",
    "\n",
    "tokens_unique, tokens_repeated, tokens_discarded, tokens_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ec082",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_unique = tokens_unique / tokens_all\n",
    "fraction_exchanged = tokens_repeated / tokens_all\n",
    "\n",
    "fraction_unique, fraction_exchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba36a3",
   "metadata": {},
   "source": [
    "#### vary T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = np.linspace(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_unique_total = {f: 0 for f in factors}\n",
    "f_repeated_total = {f: 0 for f in factors}\n",
    "f_discarded_total = {f: 0 for f in factors}\n",
    "f_used_total ={f: 0 for f in factors}\n",
    "\n",
    "for f in factors:\n",
    "    f_used = f*dfs[\"Eij\"]*dfs[\"dijtokens\"]\n",
    "    f_existing = dfs[\"dijtokens\"]\n",
    "    f_unique_lists, f_repeated_lists, f_discarded_lists = get_unique_repeated_discarded(f_used, f_existing)\n",
    "    \n",
    "    f_unique = pd.DataFrame(f_unique_lists, \n",
    "                            columns=used.columns, \n",
    "                            index=used.index)\n",
    "    f_repeated = pd.DataFrame(f_repeated_lists, \n",
    "                            columns=used.columns, \n",
    "                            index=used.index)\n",
    "    f_discarded = pd.DataFrame(f_discarded_lists, \n",
    "                               columns=used.columns, \n",
    "                               index=used.index)\n",
    "    drop_total(f_unique)\n",
    "    drop_total(f_repeated)\n",
    "    drop_total(f_discarded)\n",
    "    f_unique_total[f] += f_unique.sum().sum()/10**9\n",
    "    f_repeated_total[f] += f_repeated.sum().sum()/10**9\n",
    "    f_discarded_total[f] += f_discarded.sum().sum()/10**9\n",
    "    f_used_total[f] += f_unique.sum().sum()/10**9 + f_repeated.sum().sum()/10**9\n",
    "\n",
    "# f_unique_total, f_repeated_total, f_discarded_total, f_used_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_total = list(f_unique_total.values())\n",
    "repeated_total = list(f_repeated_total.values())\n",
    "discarded_total = list(f_repeated_total.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "if not isinstance(ax, list):\n",
    "    ax = [ax, None]\n",
    "  \n",
    "factorsT = [elem*T/10**9 for elem in factors]\n",
    "unique_percent = [u/(u+r)*100 for u, r in zip(unique_total, repeated_total)]\n",
    "# _ = ax[0].plot(factorsT, unique_total, marker=\"o\", linestyle=\"\", color=\"green\", label=\"unique\")\n",
    "# _ = ax[0].plot(factorsT, [a+b for a,b in zip(unique_total, repeated_total)], marker=\"o\", linestyle=\"\", color=\"orange\", label=\"repeated\")\n",
    "_ = ax[0].fill_between(factorsT, 0, unique_total, color=\"green\", alpha=0.5, label=\"unique\")\n",
    "_ = ax[0].fill_between(factorsT, unique_total, [a+b for a,b in zip(unique_total, repeated_total)], color=\"orange\", alpha=0.5, label=\"repeated\")\n",
    "ax[0].set_xlim([0, T/10**9])\n",
    "ax[0].set_ylim([0, T/10**9])\n",
    "ax[0].set_xlabel(\"t [10^9 tokens]\")\n",
    "ax[0].set_ylabel(\"t [10^9 tokens]\")\n",
    "_ = ax[0].legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "\n",
    "ax2 = ax[0].twinx()\n",
    "ax2.plot(factorsT, unique_percent, color=\"green\", label=\"unique percentage\")\n",
    "ax2.set_ylim([0, 100])\n",
    "ax2.plot([Tthr/10**9, Tthr/10**9], [0, 100], linestyle=\":\", color=\"k\", label=\"T_thr\")\n",
    "_ = ax2.set_ylabel(\"unique percentage [%]\")\n",
    "_ = ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figs/data_overview_3.png\", facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a21194",
   "metadata": {},
   "source": [
    "### Merged Datasets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43ad6eda",
   "metadata": {},
   "source": [
    "dfs[\"dijbytes\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdf5c018",
   "metadata": {},
   "source": [
    "dfs[\"dijtokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(_dfs, _name):\n",
    "    _dfs[f\"{_name}_MERGED\"] = _dfs[_name].copy()\n",
    "    \n",
    "    # 1. merge sv, no, da, is -> nd\n",
    "    _dfs[f\"{_name}_MERGED\"]['nd'] = _dfs[f\"{_name}_MERGED\"]['sv']\n",
    "    for lang in [\"sv\", \"no\", \"da\", \"is\"]:\n",
    "        if lang != \"sv\":\n",
    "            _dfs[f\"{_name}_MERGED\"]['nd'] += _dfs[f\"{_name}_MERGED\"][lang] \n",
    "        _dfs[f\"{_name}_MERGED\"].drop(lang, axis=1, inplace=True)\n",
    "        \n",
    "    # 2. merge books_hq and conversational for lang=nd\n",
    "    a1 = _dfs[f\"{_name}_MERGED\"].loc[\"books_hq\", \"nd\"]\n",
    "    a2 = _dfs[f\"{_name}_MERGED\"].loc[\"conversational\", \"nd\"]\n",
    "    _dfs[f\"{_name}_MERGED\"].loc[\"books_conv\"] = {\"nd\": a1+a2, \"en\": 0, \"cd\": 0, \"total\": 0}\n",
    "    _dfs[f\"{_name}_MERGED\"].loc[\"books_hq\", \"nd\"] = 0\n",
    "    _dfs[f\"{_name}_MERGED\"].loc[\"conversational\", \"nd\"] = 0\n",
    "    \n",
    "    # 3. merge wiki languages\n",
    "    a1 = _dfs[f\"{_name}_MERGED\"].loc[\"wiki\", \"nd\"]\n",
    "    a2 = _dfs[f\"{_name}_MERGED\"].loc[\"wiki\", \"en\"]\n",
    "    _categories = _dfs[f\"{_name}_MERGED\"].index.tolist()\n",
    "    _dfs[f\"{_name}_MERGED\"][\"all\"] = [0.0 for idx in _categories]\n",
    "    _dfs[f\"{_name}_MERGED\"].loc[\"wiki\", \"all\"] = a1 + a2\n",
    "    _dfs[f\"{_name}_MERGED\"].loc[\"wiki\", \"nd\"] = 0\n",
    "    _dfs[f\"{_name}_MERGED\"].loc[\"wiki\", \"en\"] = 0\n",
    "    \n",
    "    # 4a. reorder columns\n",
    "    _dfs[f\"{_name}_MERGED\"] = _dfs[f\"{_name}_MERGED\"][['nd', 'en', 'cd', 'all', 'total']]\n",
    "    \n",
    "    # 4b. reorder rows\n",
    "    _categories_new = [_categories[0]] + [_categories[-1]] + _categories[1:-1]\n",
    "    _dfs[f\"{_name}_MERGED\"] = _dfs[f\"{_name}_MERGED\"].reindex(_categories_new)\n",
    "    \n",
    "    # return\n",
    "    return _dfs\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab461185",
   "metadata": {},
   "source": [
    "dfs = merge(dfs, \"dijbytes\")\n",
    "dfs[\"dijbytes_MERGED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = merge(dfs, \"dijtokens\")\n",
    "# dfs[\"dijtokens_MERGED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13789557",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = merge(dfs, \"Fijtokens\")\n",
    "drop_total(dfs[\"Fijtokens_MERGED\"])\n",
    "add_total(dfs[\"Fijtokens_MERGED\"])\n",
    "totex(dfs[\"Fijtokens_MERGED\"].applymap(lambda x: f\"{x:.2f}\"), \"Fijtokens_MERGED\", header=\"\\\\begin{tabular}{c||c|c|c|c||c}\")\n",
    "dfs[\"Fijtokens_MERGED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b097e",
   "metadata": {},
   "source": [
    "# NUMBERS SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of tokens\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of rij\n",
    "1/m1, 1/m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum epochs for t=T\n",
    "maxE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of tokens possible with NeMo Megatron\n",
    "Tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9663275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of tokens where data start to get repeated\n",
    "Tthr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d683d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens unique/repeated/discarded for t=T, absolute\n",
    "tokens_unique, tokens_repeated, tokens_discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens unique/repeated/discarded for t=T, relative\n",
    "fraction_unique, fraction_exchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32b610",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3dda7703",
   "metadata": {},
   "source": [
    "_dfs_dijtokens = dfs[\"dijtokens\"].copy()\n",
    "drop_total(_dfs_dijtokens)\n",
    "dfs[\"Fijtokens_rounded\"] = pd.DataFrame(dfs[\"Eij_rounded\"].values*_dfs_dijtokens.values/T*100, \n",
    "                                   columns=dfs[\"Eij_rounded\"].columns, \n",
    "                                   index=dfs[\"Eij_rounded\"].index)\n",
    "dfs[\"Fijtokens_rounded\"] = dfs[\"Fijtokens_rounded\"].fillna(0)\n",
    "add_total(dfs[\"Fijtokens_rounded\"])\n",
    "\n",
    "totex(dfs[\"Fijtokens_rounded\"].applymap(lambda x: f\"{x:.2f}\"), \"Fijtokens_rounded\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"Fijtokens_rounded\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ce236a5",
   "metadata": {},
   "source": [
    "factor = dfs[\"Fijtokens_rounded\"].loc[\"total\", \"total\"]/100\n",
    "factor\n",
    "\n",
    "dfs[\"Fijtokens_rounded_normalized\"] = dfs[\"Fijtokens_rounded\"].applymap(lambda x: x/factor)\n",
    "\n",
    "totex(dfs[\"Fijtokens_rounded_normalized\"].applymap(lambda x: f\"{x:.2f}\"), \"Fijtokens_rounded_normalized\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"Fijtokens_rounded_normalized\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74c40fde",
   "metadata": {},
   "source": [
    "dfs[\"Fijtokens\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2055a1df",
   "metadata": {},
   "source": [
    "dfs[\"Fijtokens_rounded_normalized_ratio\"] = dfs[\"Fijtokens_rounded_normalized\"]/dfs[\"Fijtokens\"]\n",
    "dfs[\"Fijtokens_rounded_normalized_ratio\"] = dfs[\"Fijtokens_rounded_normalized_ratio\"].fillna(0)\n",
    "totex(dfs[\"Fijtokens_rounded_normalized_ratio\"].applymap(lambda x: f\"{x:.2f}\"), \"Fijtokens_rounded_normalized_ratio\", header=\"\\\\begin{tabular}{c||c|c|c|c|c|c||c}\")\n",
    "dfs[\"Fijtokens_rounded_normalized_ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc1979",
   "metadata": {},
   "source": [
    "### Minimum Hypothesis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a3b056f",
   "metadata": {},
   "source": [
    "a = T*dfs[\"Fijtokens\"]/100.\n",
    "a"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d810ad35",
   "metadata": {},
   "source": [
    "b = dfs[\"dijtokens\"]/100*100\n",
    "b"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91796b0b",
   "metadata": {},
   "source": [
    "c = pd.concat([a,b]).min(level=0)\n",
    "c.drop(\"total\", axis=0, inplace=True)\n",
    "c.drop(\"total\", axis=1, inplace=True)\n",
    "c[\"total\"] = c.apply(lambda x: sum(x), axis=1)\n",
    "c.loc[\"total\"] = c.apply(lambda x: sum(x), axis=0)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0d05b",
   "metadata": {},
   "source": [
    "# HEATMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e12bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(dfs[\"dijbytes\"], annot=True)\n",
    "ax.set_title('dataset sizes [bytes]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(dfs[\"Wij\"], annot=True)\n",
    "ax.set_title('weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc411fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(dfs[\"fijbytes\"], annot=True)\n",
    "ax.set_title('dataset_size [%]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(dfs[\"Fijbytes\"], annot=True)\n",
    "ax.set_title('dataset_size weighted [%]')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gpt-sw3-tokenizer",
   "language": "python",
   "name": "venv-gpt-sw3-tokenizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
