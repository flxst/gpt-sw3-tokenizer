# - unit: tokens (=bytes/2)
# - exact numbers taken from /data/tokenized on ICE2
# - these numbers use the 64k tokenizer after the "special token fix",
#   i.e. with pad_id = 0, unk_id = 1, bos_id = 2, eos_id = 3
#
category,sv,en,no,da,is,cd
articles,3636947113,49711880278,0,56785974,0,0
books_hq,194756254,23992495599,0,0,0,0
code,0,0,0,0,0,37169954570
conversational,16495721559,21148288412,153171267,722717726,41369041,0
math,2516022111,2714742862,0,0,0,0
misc,4768103336,13748796281,13381445767,5761025345,2907953600,0
web_commoncrawl,45601369589,14137185319,23494584912,28384525764,2568428954,0
web_sources,1710849195,0,0,497298109,0,0
wiki,266865214,3730924622,126894083,99707612,14921138,0
