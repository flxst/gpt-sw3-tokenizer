"""
EXECUTION: python script_test_conversion_from_sp_to_hf.py

PURPOSE: the script
         - loads a SP tokenizer from a <model_file> (hardcoded)
         - loads the corresponding HF tokenizer from a <tokenizer_vocab> file and a <tokenizer_merge> file
           (Note: the <tokenizer_merge> file can be created by script_merge.py)
         - compares the two tokenizers (vocab & examples)
"""

from os.path import join
import sentencepiece as spm
from tokenizers.implementations.sentencepiece_bpe import SentencePieceBPETokenizer
from tokenizers.normalizers import NFC

from os.path import abspath, dirname
import sys
BASE_DIR = abspath(dirname(dirname(dirname(abspath(__file__)))))
print(f">>> BASE_DIR: {BASE_DIR}")
sys.path.append(BASE_DIR)

from src.env import Env
from src.test_data import TEST_EXAMPLES
import json


def print_sp_vs_hf_for_i(_sp, _hf, _i):
    print()
    print(f"> i = {_i}")
    print(f"  --- SP ---")
    print(f"  sp.id_to_piece({_i}) = {_sp.id_to_piece(_i)}")
    print(f"  sp.decode([{_i}]) = {_sp.decode([_i])}")
    print(f"  repr(sp.decode([{_i}])) = {repr(_sp.decode([_i]))}")
    print(f"  --- HF ---")
    print(f"  hf.id_to_token({_i}) = {_hf.id_to_token(_i)}")
    print(f"  hf.decode([{_i}]) = {_hf.decode([_i])}")
    print(f"  repr(hf.decode([{_i}])) = {repr(_hf.decode([_i]))}")


def main():
    model_name = "180051_SP-uNone-d1-p1-w2-c1-f0-bf1-cc0.9999-x1-v64000_tokenizer2"

    env = Env(".")
    model_file = join(env.output, model_name, "model.model")
    vocab_file = join(env.output, model_name, "tokenizer_vocab.json")
    merge_file = join(env.output, model_name, "tokenizer_merge.txt")

    sp = spm.SentencePieceProcessor(model_file=model_file)

    with open(vocab_file, "r") as f:
        vocab = json.load(f)
    with open(merge_file, "r") as f:
        merges = f.readlines()
        merges = [(elem.split()[0], elem.split()[1]) for elem in merges]

    special_tokens = [
        elem for elem in vocab.keys()
        if (elem.startswith("<|") and elem.endswith("|>"))
    ]
    byte_fallbacks = [
        elem for elem in vocab.keys()
        if (elem.startswith("<0x") and elem.endswith(">"))
    ]

    hf = SentencePieceBPETokenizer(vocab=vocab, merges=merges, add_prefix_space=True)
    hf.normalizer = NFC()
    hf.add_special_tokens(special_tokens)
    hf.add_special_tokens(byte_fallbacks)

    ##########################
    # 1. vocab
    ##########################
    print()
    print("========================")
    print("===== 1. VOCAB =========")
    print("========================")

    for i in [0, 1, 63423, 63999]:
        print_sp_vs_hf_for_i(sp, hf, i)

    unequal = list()
    for i in range(64000):
        if sp.id_to_piece(i) != hf.id_to_token(i) or sp.decode([i]) != hf.decode([i]) or repr(sp.decode([i])) != repr(hf.decode([i])):
            unequal.append(i)

    print()
    print(f">>> SP != HF: {unequal}")
    for j in [0, 1, -1]:
        print_sp_vs_hf_for_i(sp, hf, unequal[j])

    ##########################
    # 2. examples
    ##########################
    print()
    print("========================")
    print("===== 2. EXAMPLES ======")
    print("========================")
    examples = [
        "This is an example of text generated by a model. It is completely made up.",
        "Hello, my name is Ariel. Hej, mitt namn Ã¤r Ariel."
    ]
    examples += TEST_EXAMPLES
    for example in examples:
        sp_encoded = sp.encode(example)
        sp_decoded = sp.decode(sp_encoded)
        sp_decoded_elementwise = [sp.decode(elem) for elem in sp_encoded]

        hf_encoded = hf.encode(example).ids
        hf_decoded = hf.decode(hf_encoded)
        hf_decoded_elementwise = [hf.decode([elem]) for elem in hf_encoded]

        if sp_encoded == hf_encoded and sp_decoded == hf_decoded and sp_decoded_elementwise == hf_decoded_elementwise:
            equal = True
        else:
            equal = False
        if not equal:
            print()
            print(f"> example = {example}")
            print(f"  --- SP ---")
            print(f"  encoded (whole example) = {sp_encoded}")
            print(f"  decoded (whole example) = '{sp_decoded}'")
            print(f"  decoded (elementwise)   = {sp_decoded_elementwise}")
            print(f"  --- HF ---")
            print(f"  encoded (whole example) = {hf_encoded}")
            print(f"  decoded (whole example) = '{hf_decoded}'")
            print(f"  decoded (elementwise)   = {hf_decoded_elementwise}")
            print()
            print(f">>> SP == HF: {equal}")

    # print(sp)


if __name__ == "__main__":
    main()
